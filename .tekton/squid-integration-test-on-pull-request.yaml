apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  annotations:
    build.appstudio.openshift.io/repo: https://github.com/konflux-ci/caching?rev={{revision}}
    build.appstudio.redhat.com/commit_sha: '{{revision}}'
    build.appstudio.redhat.com/pull_request_number: '{{pull_request_number}}'
    build.appstudio.redhat.com/target_branch: '{{target_branch}}'
    pipelinesascode.tekton.dev/max-keep-runs: "3"
    pipelinesascode.tekton.dev/on-cel-expression: |
      event == "pull_request" && target_branch == "main"
  labels:
    appstudio.openshift.io/application: caching
    appstudio.openshift.io/component: squid
    pipelines.appstudio.openshift.io/type: test
  name: squid-integration-test-on-pull-request
  namespace: konflux-vanguard-tenant
spec:
  params:
    - name: test-name
      value: squid-openshift-e2e
    - name: ocp-version
      value: "4.17"
    - name: test-event-type
      value: pull_request
    - name: machine-type
      value: m5.xlarge

  pipelineSpec:
    description: |-
      This pipeline automates the process of running end-to-end tests for Squid
      on an ephemeral OpenShift cluster using EaaS (Environment as a Service).
    params:
      - name: SNAPSHOT
        description: 'The JSON string representing the snapshot of the application under test.'
        default: '{"components": [{"name":"squid", "containerImage": "quay.io/redhat-user-workloads/konflux-vanguard-tenant/caching/squid:latest"}]}'
        type: string
      - name: test-name
        description: 'The name of the test corresponding to a defined Konflux integration test.'
        default: 'squid-e2e'
      - name: ocp-version
        description: 'The OpenShift version to use for the ephemeral cluster deployment.'
        type: string
        default: "4.17"
      - name: test-event-type
        description: 'Indicates if the test is triggered by a Pull Request or Push event.'
        default: 'pull_request'
      - name: machine-type
        description: 'The EC2 instance type for cluster worker nodes (amd64 or arm64).'
        type: string
        default: "m5.xlarge"
    
    tasks:
      - name: test-metadata
        taskRef:
          resolver: git
          params:
            - name: url
              value: https://github.com/konflux-ci/tekton-integration-catalog.git
            - name: revision
              value: main
            - name: pathInRepo
              value: common/tasks/test-metadata/0.1/test-metadata.yaml
        params:
          - name: SNAPSHOT
            value: $(params.SNAPSHOT)
          - name: test-name
            value: $(context.pipelineRun.name)

      # Extract component images from SNAPSHOT for multi-component integration test
      # This is required because our test needs both squid and squid-tester images
      - name: parse-snapshot
        runAfter:
          - test-metadata
        taskSpec:
          params:
            - name: SNAPSHOT
              type: string
          results:
            - name: squid-image
              description: Container image for the squid component
            - name: squid-tester-image
              description: Container image for the squid-tester component
          steps:
            - name: parse
              image: quay.io/konflux-ci/konflux-test:v1.4.31@sha256:a7cae9e96663e277a3904d0c78630508ddb6cc8eebaa912a840bd20f68dcaad1
              script: |
                #!/bin/bash
                set -euo pipefail
                
                echo "Parsing SNAPSHOT to extract component images..."
                echo '$(params.SNAPSHOT)' | jq . | tee /tmp/snapshot.json
                
                # Extract squid image
                squid_image=$(echo '$(params.SNAPSHOT)' | jq -r '.components[] | select(.name=="squid") | .containerImage')
                if [ -z "$squid_image" ] || [ "$squid_image" = "null" ]; then
                  echo "ERROR: Could not find squid component in SNAPSHOT"
                  echo "Available components:"
                  echo '$(params.SNAPSHOT)' | jq -r '.components[].name'
                  exit 1
                fi
                echo "Found squid image: $squid_image"
                echo -n "$squid_image" > $(results.squid-image.path)
                
                # Extract squid-tester image (optional)
                # If not in SNAPSHOT, we'll use the default from values.yaml during helm install
                tester_image=$(echo '$(params.SNAPSHOT)' | jq -r '.components[] | select(.name=="squid-tester") | .containerImage')
                if [ -z "$tester_image" ] || [ "$tester_image" = "null" ]; then
                  echo "INFO: squid-tester not found in SNAPSHOT"
                  echo "This is expected when PR only modifies squid (not tests)"
                  echo "Will use default test image from values.yaml: quay.io/konflux-ci/caching/squid-test:latest"
                  tester_image=""
                else
                  echo "Found squid-tester image in SNAPSHOT: $tester_image"
                fi
                echo -n "$tester_image" > $(results.squid-tester-image.path)
        params:
          - name: SNAPSHOT
            value: $(params.SNAPSHOT)

      # Step 1: Provision EaaS namespace
      - name: provision-eaas-space
        when:
          - input: "$(tasks.test-metadata.results.test-event-type)"
            operator: in
            values: ["pull_request"]
        runAfter:
          - test-metadata
        taskRef:
          resolver: git
          params:
            - name: url
              value: https://github.com/konflux-ci/build-definitions.git
            - name: revision
              value: main
            - name: pathInRepo
              value: task/eaas-provision-space/0.1/eaas-provision-space.yaml
        params:
          - name: ownerName
            value: $(context.pipelineRun.name)
          - name: ownerUid
            value: $(context.pipelineRun.uid)
      
      # Step 2-5: Provision ephemeral cluster and retrieve credentials
      - name: provision-cluster
        when:
          - input: "$(tasks.test-metadata.results.test-event-type)"
            operator: in
            values: ["pull_request"]
        runAfter:
          - provision-eaas-space
        taskSpec:
          results:
            - name: clusterName
              value: "$(steps.create-cluster.results.clusterName)"
          steps:
            - name: get-supported-versions
              ref:
                resolver: git
                params:
                  - name: url
                    value: https://github.com/konflux-ci/build-definitions.git
                  - name: revision
                    value: main
                  - name: pathInRepo
                    value: stepactions/eaas-get-supported-ephemeral-cluster-versions/0.1/eaas-get-supported-ephemeral-cluster-versions.yaml
              params:
                - name: eaasSpaceSecretRef
                  value: $(tasks.provision-eaas-space.results.secretRef)
            - name: get-latest-version
              ref:
                resolver: git
                params:
                  - name: url
                    value: https://github.com/konflux-ci/build-definitions.git
                  - name: revision
                    value: main
                  - name: pathInRepo
                    value: stepactions/eaas-get-latest-openshift-version-by-prefix/0.1/eaas-get-latest-openshift-version-by-prefix.yaml
              params:
                - name: prefix
                  value: "$(steps.get-supported-versions.results.versions[0])."
            - name: create-cluster
              ref:
                resolver: git
                params:
                  - name: url
                    value: https://github.com/konflux-ci/build-definitions.git
                  - name: revision
                    value: main
                  - name: pathInRepo
                    value: stepactions/eaas-create-ephemeral-cluster-hypershift-aws/0.1/eaas-create-ephemeral-cluster-hypershift-aws.yaml
              params:
                - name: eaasSpaceSecretRef
                  value: $(tasks.provision-eaas-space.results.secretRef)
                - name: version
                  value: "$(steps.get-latest-version.results.version)"
                - name: instanceType
                  value: $(params.machine-type)
                - name: timeout
                  value: "45m"
      
      # Step 6: Run E2E tests
      - name: squid-e2e-tests
        timeout: 2h
        when:
          - input: "$(tasks.test-metadata.results.test-event-type)"
            operator: in
            values: ["pull_request"]
        runAfter:
          - provision-cluster
          - parse-snapshot
        taskSpec:
          params:
            - name: squid-image
            - name: tester-image
            - name: git-url
            - name: git-revision
          volumes:
            - name: credentials
              emptyDir: {}
          steps:
            - name: get-kubeconfig
              ref:
                resolver: git
                params:
                  - name: url
                    value: https://github.com/konflux-ci/build-definitions.git
                  - name: revision
                    value: main
                  - name: pathInRepo
                    value: stepactions/eaas-get-ephemeral-cluster-credentials/0.1/eaas-get-ephemeral-cluster-credentials.yaml
              params:
                - name: eaasSpaceSecretRef
                  value: $(tasks.provision-eaas-space.results.secretRef)
                - name: clusterName
                  value: "$(tasks.provision-cluster.results.clusterName)"
                - name: credentials
                  value: credentials
            - name: debug-list-secrets
              image: quay.io/konflux-ci/konflux-test:v1.4.31@sha256:a7cae9e96663e277a3904d0c78630508ddb6cc8eebaa912a840bd20f68dcaad1
              script: |
                #!/bin/bash
                set -euo pipefail
                echo "=== DEBUG: Listing image pull secrets in Konflux namespace ==="
                echo "This helps identify the correct labelSelector for copy-secrets step"
                echo "NOTE: This runs in the Konflux cluster context (where pipeline is running)"
                echo ""
                echo "Current namespace: $(oc project -q 2>/dev/null || echo 'unknown')"
                echo ""
                echo "Image pull secrets (type=kubernetes.io/dockerconfigjson):"
                oc get secrets -o json | \
                  jq -r '.items[] | select(.type=="kubernetes.io/dockerconfigjson") | 
                    "\(.metadata.name) - Labels: \(.metadata.labels // {})"' || echo "No secrets found or jq failed"
                echo ""
                echo "Trying labelSelector: appstudio.redhat.com/internal=true"
                oc get secrets -l "appstudio.redhat.com/internal=true" -o name || echo "No secrets match this label"
                echo ""
                echo "If no secrets found, check if secrets exist with: oc get secrets --show-labels"
                echo "=== END DEBUG ==="
            - name: create-namespace
              image: quay.io/konflux-ci/konflux-test:v1.4.31@sha256:a7cae9e96663e277a3904d0c78630508ddb6cc8eebaa912a840bd20f68dcaad1
              env:
                - name: KUBECONFIG
                  value: "/credentials/$(steps.get-kubeconfig.results.kubeconfig)"
              volumeMounts:
                - name: credentials
                  mountPath: /credentials
              script: |
                #!/bin/bash
                set -euo pipefail
                echo "Creating caching namespace on ephemeral cluster..."
                
                # Create namespace with Helm ownership labels so Helm can manage it
                # This is required because copy-secrets needs the namespace to exist,
                # but Helm also wants to manage it from templates/namespace.yaml
                cat <<EOF | oc apply -f -
                apiVersion: v1
                kind: Namespace
                metadata:
                  name: caching
                  labels:
                    app.kubernetes.io/managed-by: Helm
                  annotations:
                    meta.helm.sh/release-name: squid
                    meta.helm.sh/release-namespace: caching
                EOF
                
                echo "Namespace created with Helm ownership labels"
            - name: copy-secrets
              ref:
                resolver: git
                params:
                  - name: url
                    value: https://github.com/konflux-ci/build-definitions.git
                  - name: revision
                    value: main
                  - name: pathInRepo
                    value: stepactions/eaas-copy-secrets-to-ephemeral-cluster/0.1/eaas-copy-secrets-to-ephemeral-cluster.yaml
              params:
                - name: credentials
                  value: credentials
                - name: kubeconfig
                  value: "$(steps.get-kubeconfig.results.kubeconfig)"
                - name: namespace
                  value: "caching"
                - name: labelSelector
                  value: "appstudio.redhat.com/internal=true"
            - name: deploy-and-test
              image: quay.io/konflux-ci/konflux-test:v1.4.31@sha256:a7cae9e96663e277a3904d0c78630508ddb6cc8eebaa912a840bd20f68dcaad1
              env:
                - name: KUBECONFIG
                  value: "/credentials/$(steps.get-kubeconfig.results.kubeconfig)"
              volumeMounts:
                - name: credentials
                  mountPath: /credentials
              script: |
                #!/bin/bash
                set -euo pipefail
                
                echo "Using kubeconfig at: $KUBECONFIG"
                
                # Install helm
                echo "Installing Helm..."
                curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
                helm version
                
                # Verify cluster access and permissions
                echo "Verifying OpenShift cluster..."
                oc version
                echo "Checking permissions..."
                oc auth can-i create customresourcedefinitions || echo "WARNING: No CRD permissions"
                oc auth can-i '*' '*' --all-namespaces && echo "Confirmed: cluster-admin access" || echo "WARNING: Limited permissions"
                echo "Cluster ready"
                
                echo "Cloning repository for Helm chart..."
                git clone $(params.git-url) /workspace/source
                cd /workspace/source
                git checkout $(params.git-revision)
                
                echo "Deploying Squid via Helm..."
                # Use the chart's default namespace (defined in values.yaml)
                # The chart's templates/namespace.yaml will create and manage this namespace
                namespace="caching"
                echo "Using namespace: $namespace"
                
                # Verify that image pull secrets were copied
                echo "Checking for image pull secrets in $namespace namespace..."
                pull_secrets=$(oc get secrets -n "$namespace" -o json | \
                  jq -r '.items[] | select(.type=="kubernetes.io/dockerconfigjson") | .metadata.name' 2>/dev/null || echo "")
                
                if [ -n "$pull_secrets" ]; then
                  echo "Found $(echo "$pull_secrets" | wc -w) image pull secret(s):"
                  echo "$pull_secrets"
                  
                  # Build --set imagePullSecrets arguments for Helm
                  secret_args=""
                  idx=0
                  for secret in $pull_secrets; do
                    secret_args="$secret_args --set imagePullSecrets[$idx].name=$secret"
                    idx=$((idx + 1))
                  done
                  echo "Will configure Helm chart with these secrets"
                else
                  echo "WARNING: No image pull secrets found in $namespace namespace"
                  echo "If images are in a private registry, the deployment may fail with ImagePullBackOff"
                  secret_args=""
                fi
                
                # Deploy Squid
                # Note: No --create-namespace flag, the chart creates it via templates/namespace.yaml
                echo "Adding jetstack Helm repository for dependencies..."
                helm repo add jetstack https://charts.jetstack.io 2>/dev/null || true
                helm repo update
                cd squid
                helm dependency build
                
                # Parse image references (handle both tag and digest formats)
                # Format: registry/repo:tag OR registry/repo@sha256:digest
                squid_img="$(params.squid-image)"
                if [[ "$squid_img" == *"@"* ]]; then
                  # Digest format: quay.io/repo@sha256:abc
                  squid_repo="${squid_img%@*}"
                  squid_tag="${squid_img#*@}"
                else
                  # Tag format: quay.io/repo:tag
                  squid_repo="${squid_img%:*}"
                  squid_tag="${squid_img##*:}"
                fi
                
                tester_img="$(params.tester-image)"
                # If tester image is not in SNAPSHOT, we'll skip setting it in Helm
                # and let Helm use the default from values.yaml (quay.io/konflux-ci/caching/squid-test:latest)
                if [ -n "$tester_img" ]; then
                  if [[ "$tester_img" == *"@"* ]]; then
                    tester_repo="${tester_img%@*}"
                    tester_tag="${tester_img#*@}"
                  else
                    tester_repo="${tester_img%:*}"
                    tester_tag="${tester_img##*:}"
                  fi
                  echo "Squid image: repository=$squid_repo tag=$squid_tag"
                  echo "Tester image: repository=$tester_repo tag=$tester_tag (from SNAPSHOT)"
                else
                  echo "Squid image: repository=$squid_repo tag=$squid_tag"
                  echo "Tester image: will use default from values.yaml (squid-tester not in SNAPSHOT)"
                fi
                
                echo "Checking if cert-manager is already installed on cluster..."
                # Check for cert-manager CRDs which are more reliable than deployments
                if oc get crd certificates.cert-manager.io 2>/dev/null; then
                  echo "cert-manager CRDs found, checking if cert-manager is running..."
                  if oc get deployment -n cert-manager cert-manager 2>/dev/null; then
                    echo "cert-manager is installed and running, will skip bundled installation"
                  else
                    echo "WARNING: cert-manager CRDs exist but deployment not found"
                    echo "This may indicate a partial installation. Will still skip bundled installation to avoid conflicts."
                  fi
                else
                  echo "cert-manager not found on cluster, installing it separately..."
                  
                  # Install cert-manager separately from official jetstack repo
                  echo "Installing cert-manager v1.19.1 (this may take 5-10 minutes)..."
                  helm install cert-manager jetstack/cert-manager \
                    --namespace cert-manager \
                    --create-namespace \
                    --version v1.19.1 \
                    --set installCRDs=true \
                    --wait \
                    --timeout=15m \
                    --debug
                  
                  echo "Waiting for cert-manager components to be fully ready..."
                  oc wait --for=condition=Available --timeout=5m \
                    deployment/cert-manager \
                    deployment/cert-manager-webhook \
                    deployment/cert-manager-cainjector \
                    -n cert-manager || echo "WARNING: Some cert-manager components may not be ready"
                  
                  echo "cert-manager installation complete!"
                  
                  # Install trust-manager which is required for the squid chart
                  # Using v0.20.2 to match the version in squid/Chart.yaml dependencies
                  echo "Installing trust-manager v0.20.2..."
                  helm install trust-manager jetstack/trust-manager \
                    --namespace cert-manager \
                    --version v0.20.2 \
                    --wait \
                    --timeout=10m \
                    --debug
                  
                  echo "Waiting for trust-manager to be ready..."
                  oc wait --for=condition=Available --timeout=3m \
                    deployment/trust-manager \
                    -n cert-manager || echo "WARNING: trust-manager may not be ready"
                  
                  echo "trust-manager installation complete!"
                fi
                
                echo "Installing Squid chart (cert-manager bundled installation disabled)..."
                # Build helm command - only set tester image if it was provided in SNAPSHOT
                helm_cmd="helm install squid . \
                  --namespace \"$namespace\" \
                  --set namespace.name=\"$namespace\" \
                  --set envSettings.release.squid.image.repository=\"$squid_repo\" \
                  --set envSettings.release.squid.image.tag=\"$squid_tag\" \
                  --set mirrord.enabled=false \
                  --set installCertManagerComponents=false \
                  --set cert-manager.enabled=false \
                  --set trust-manager.enabled=false \
                  $secret_args \
                  --wait \
                  --timeout=5m \
                  --debug"
                
                # Only override test image if squid-tester was in SNAPSHOT
                if [ -n "$tester_img" ]; then
                  helm_cmd="$helm_cmd \
                    --set envSettings.release.test.image.repository=\"$tester_repo\" \
                    --set envSettings.release.test.image.tag=\"$tester_tag\""
                fi
                
                echo "Running: $helm_cmd"
                if ! eval "$helm_cmd"; then
                  
                  echo "ERROR: Squid Helm installation failed or timed out!"
                  echo "======================================"
                  echo "Collecting diagnostics..."
                  echo ""
                  
                  echo "=== NAMESPACE RESOURCES ==="
                  oc get all -n "$namespace" || true
                  echo ""
                  
                  echo "=== POD STATUS ==="
                  oc get pods -n "$namespace" -o wide || true
                  echo ""
                  
                  echo "=== POD DESCRIPTIONS (Events) ==="
                  oc describe pods -n "$namespace" || true
                  echo ""
                  
                  echo "=== DEPLOYMENT STATUS ==="
                  oc describe deployment/squid -n "$namespace" || true
                  echo ""
                  
                  echo "=== POD LOGS (last 100 lines) ==="
                  for pod in $(oc get pods -n "$namespace" -l app.kubernetes.io/name=squid -o jsonpath='{.items[*].metadata.name}' 2>/dev/null); do
                    echo "--- Logs from pod: $pod ---"
                    oc logs -n "$namespace" "$pod" --tail=100 --all-containers=true || echo "Could not retrieve logs for $pod"
                    echo ""
                  done
                  
                  echo "=== REPLICASET STATUS ==="
                  oc describe replicaset -n "$namespace" || true
                  echo ""
                  
                  echo "=== NAMESPACE EVENTS ==="
                  oc get events -n "$namespace" --sort-by='.lastTimestamp' || true
                  
                  exit 1
                fi
                
                echo "Squid deployed successfully!"
                echo "Checking pod status..."
                oc get pods -n "$namespace"
                oc get all -n "$namespace"
                
                echo "Running Helm tests..."
                if ! helm test squid --namespace "$namespace" --timeout 90m; then
                  echo "========================================"
                  echo "ERROR: Helm test failed!"
                  echo "========================================"
                  echo ""
                  echo "=== Retrieving Ginkgo E2E Test Logs from squid-test pod ==="
                  echo ""
                  if oc logs -n "$namespace" squid-test --tail=500 2>&1; then
                    echo ""
                    echo "=== End of test pod logs ==="
                  else
                    echo "WARNING: Could not retrieve test pod logs (pod may have been deleted)"
                    echo "Listing pods to verify:"
                    oc get pods -n "$namespace"
                  fi
                  echo ""
                  exit 1
                fi
                
                echo "All E2E tests passed!"
        params:
          - name: squid-image
            value: "$(tasks.parse-snapshot.results.squid-image)"
          - name: tester-image
            value: "$(tasks.parse-snapshot.results.squid-tester-image)"
          - name: git-url
            value: "$(tasks.test-metadata.results.git-url)"
          - name: git-revision
            value: "$(tasks.test-metadata.results.git-revision)"
    
    finally:
      - name: cleanup-report
        taskSpec:
          steps:
            - name: report
              image: registry.redhat.io/ubi9/ubi-minimal:latest
              script: |
                #!/bin/bash
                echo "Cleanup complete"
                echo "Ephemeral cluster and namespace will auto-delete:"
                echo "  - Namespace: 4 hours after creation"
                echo "  - Cluster: 2 hours after creation or when PipelineRun is deleted"
